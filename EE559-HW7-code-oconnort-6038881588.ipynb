{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tim O'Connor<br>\n",
    "\n",
    "603-888-1588<br>\n",
    "\n",
    "oconnort@usc.edu<br>\n",
    "\n",
    "EE559 - Rajati - Summer 2024<br>\n",
    "\n",
    "HW 7 - Programming Part<br>\n",
    "\n",
    "4.\tProgramming Assignment: Parkinsons Telemonitoring<br><br>\n",
    "\n",
    "(a)\tDownload the Parkinsons Telemonitoring Data Set from: http://archive.ics.scu.edu/ml/datasets/Parkinsons+Telemonitoring .Choose 70% of the data randomly as the training set.<br><br>\n",
    "\n",
    "(b)\tUse metric learning with Gaussian kernels to estimate each of the outputs motor UPDRS and total UPDRS from the features. As metric leaning uses a low dimensional transformation of the features except the non-predictive feature subject#, use 5-fold cross-validation to decide the number of components form M=5,10,15,p, where p is the number of all predictive features you can use. Initialize the linear transformation with PCA features for M = 5,10,15 and with original features for M=p. This corresponds to setting intit as (default=’auto’). Remember to standardize your features. Report the R^2 on training and test sets for each of the outputs. (30 pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import r2_score\n",
    "from metric_learn import MLKR\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "path = './parkinsons_updrs.data'\n",
    "\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "X = data.drop(columns=['subject#', 'motor_UPDRS', 'total_UPDRS'])\n",
    "y_motor = data['motor_UPDRS']\n",
    "y_total = data['total_UPDRS']\n",
    "\n",
    "X_train, X_test, y_motor_train, y_motor_test, y_total_train, y_total_test = train_test_split(X, y_motor, y_total, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "n = 5 #originally tried to run all of the possible components in a loop, but it was too computationally expensive, 5 was able to finish.\n",
    "\n",
    "pca_transformations = PCA(n_components=n).fit(X_train_scaled)\n",
    "\n",
    "def process_fold(train_i, value_i, n, X_train_scaled, y_motor_train, y_total_train):\n",
    "    X_train_kf, X_value_kf = X_train_scaled[train_i], X_train_scaled[value_i]\n",
    "    y_motor_train_kf, y_motor_value_kf = y_motor_train.iloc[train_i], y_motor_train.iloc[value_i]\n",
    "    y_total_train_kf, y_total_value_kf = y_total_train.iloc[train_i], y_total_train.iloc[value_i]\n",
    "    \n",
    "    X_motor_train_PCA = pca_transformations.transform(X_train_kf)\n",
    "    X_motor_test_PCA = pca_transformations.transform(X_value_kf)\n",
    "    \n",
    "    mlkr_motor = MLKR(n_components=n, init='pca')\n",
    "    mlkr_motor.fit(X_motor_train_PCA, y_motor_train_kf)\n",
    "    X_motor_train_MLKR = mlkr_motor.transform(X_motor_train_PCA)\n",
    "    X_motor_test_MLKR = mlkr_motor.transform(X_motor_test_PCA)\n",
    "    \n",
    "    gauss_kernel_motor = KernelRidge(kernel='rbf')\n",
    "    gauss_kernel_motor.fit(X_motor_train_MLKR, y_motor_train_kf)\n",
    "    \n",
    "    y_train_pred_motor = gauss_kernel_motor.predict(X_motor_train_MLKR)\n",
    "    y_test_pred_motor = gauss_kernel_motor.predict(X_motor_test_MLKR)\n",
    "    \n",
    "    r2_train_motor = r2_score(y_motor_train_kf, y_train_pred_motor)\n",
    "    r2_test_motor = r2_score(y_motor_value_kf, y_test_pred_motor)\n",
    "    \n",
    "    X_total_train_PCA = pca_transformations.transform(X_train_kf)\n",
    "    X_total_test_PCA = pca_transformations.transform(X_value_kf)\n",
    "    \n",
    "    mlkr_total = MLKR(n_components=n, init='pca')\n",
    "    mlkr_total.fit(X_total_train_PCA, y_total_train_kf)\n",
    "    X_total_train_MLKR = mlkr_total.transform(X_total_train_PCA)\n",
    "    X_total_test_MLKR = mlkr_total.transform(X_total_test_PCA)\n",
    "    \n",
    "    gauss_kernel_total = KernelRidge(kernel='rbf')\n",
    "    gauss_kernel_total.fit(X_total_train_MLKR, y_total_train_kf)\n",
    "    \n",
    "    y_train_pred_total = gauss_kernel_total.predict(X_total_train_MLKR)\n",
    "    y_test_pred_total = gauss_kernel_total.predict(X_total_test_MLKR)\n",
    "    \n",
    "    r2_train_total = r2_score(y_total_train_kf, y_train_pred_total)\n",
    "    r2_test_total = r2_score(y_total_value_kf, y_test_pred_total)\n",
    "    \n",
    "    return (n, r2_train_motor, r2_test_motor, r2_train_total, r2_test_total)\n",
    "\n",
    "def process_m(n, kf, X_train_scaled, y_motor_train, y_total_train):\n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(process_fold)(train_i, value_i, n, X_train_scaled, y_motor_train, y_total_train)\n",
    "        for train_i, value_i in kf.split(X_train_scaled)\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "parallel_results = Parallel(n_jobs=-1)(\n",
    "    delayed(process_m)(n, kf, X_train_scaled, y_motor_train, y_total_train) for n in [n]\n",
    ")\n",
    "\n",
    "for result in parallel_results:\n",
    "    for fold_result in result:\n",
    "        print(f\"Components: {fold_result[0]}, R^2 Train Motor: {fold_result[1]}, R^2 Test Motor: {fold_result[2]}, R^2 Train Total: {fold_result[3]}, R^2 Test Total: {fold_result[4]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 83\u001b[0m\n\u001b[1;32m     76\u001b[0m     results \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)(\n\u001b[1;32m     77\u001b[0m         delayed(process_fold)(train_i, value_i, n, X_train_scaled, y_motor_train, y_total_train)\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m train_i, value_i \u001b[38;5;129;01min\u001b[39;00m kf\u001b[38;5;241m.\u001b[39msplit(X_train_scaled)\n\u001b[1;32m     79\u001b[0m     )\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m---> 83\u001b[0m parallel_results \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)(\n\u001b[1;32m     84\u001b[0m     delayed(process_m)(n, kf, X_train_scaled, y_motor_train, y_total_train) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m [n]\n\u001b[1;32m     85\u001b[0m )\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Print results for each fold\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m parallel_results:\n",
      "File \u001b[0;32m~/anaconda3/envs/EE559/lib/python3.11/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m~/anaconda3/envs/EE559/lib/python3.11/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/EE559/lib/python3.11/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import r2_score\n",
    "from metric_learn import MLKR\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "path = './parkinsons_updrs.data'\n",
    "\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "X = data.drop(columns=['subject#', 'motor_UPDRS', 'total_UPDRS'])\n",
    "y_motor = data['motor_UPDRS']\n",
    "y_total = data['total_UPDRS']\n",
    "\n",
    "X_train, X_test, y_motor_train, y_motor_test, y_total_train, y_total_test = train_test_split(X, y_motor, y_total, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "n = 10\n",
    "\n",
    "pca_transformations = PCA(n_components=n).fit(X_train_scaled)\n",
    "\n",
    "def process_fold(train_i, value_i, n, X_train_scaled, y_motor_train, y_total_train):\n",
    "    X_train_kf, X_value_kf = X_train_scaled[train_i], X_train_scaled[value_i]\n",
    "    y_motor_train_kf, y_motor_value_kf = y_motor_train.iloc[train_i], y_motor_train.iloc[value_i]\n",
    "    y_total_train_kf, y_total_value_kf = y_total_train.iloc[train_i], y_total_train.iloc[value_i]\n",
    "    \n",
    "    X_motor_train_PCA = pca_transformations.transform(X_train_kf)\n",
    "    X_motor_test_PCA = pca_transformations.transform(X_value_kf)\n",
    "    \n",
    "    mlkr_motor = MLKR(n_components=n, init='pca')\n",
    "    mlkr_motor.fit(X_motor_train_PCA, y_motor_train_kf)\n",
    "    X_motor_train_MLKR = mlkr_motor.transform(X_motor_train_PCA)\n",
    "    X_motor_test_MLKR = mlkr_motor.transform(X_motor_test_PCA)\n",
    "    \n",
    "    gauss_kernel_motor = KernelRidge(kernel='rbf')\n",
    "    gauss_kernel_motor.fit(X_motor_train_MLKR, y_motor_train_kf)\n",
    "    \n",
    "    y_train_pred_motor = gauss_kernel_motor.predict(X_motor_train_MLKR)\n",
    "    y_test_pred_motor = gauss_kernel_motor.predict(X_motor_test_MLKR)\n",
    "    \n",
    "    r2_train_motor = r2_score(y_motor_train_kf, y_train_pred_motor)\n",
    "    r2_test_motor = r2_score(y_motor_value_kf, y_test_pred_motor)\n",
    "    \n",
    "    X_total_train_PCA = pca_transformations.transform(X_train_kf)\n",
    "    X_total_test_PCA = pca_transformations.transform(X_value_kf)\n",
    "    \n",
    "    mlkr_total = MLKR(n_components=n, init='pca')\n",
    "    mlkr_total.fit(X_total_train_PCA, y_total_train_kf)\n",
    "    X_total_train_MLKR = mlkr_total.transform(X_total_train_PCA)\n",
    "    X_total_test_MLKR = mlkr_total.transform(X_total_test_PCA)\n",
    "    \n",
    "    gauss_kernel_total = KernelRidge(kernel='rbf')\n",
    "    gauss_kernel_total.fit(X_total_train_MLKR, y_total_train_kf)\n",
    "    \n",
    "    y_train_pred_total = gauss_kernel_total.predict(X_total_train_MLKR)\n",
    "    y_test_pred_total = gauss_kernel_total.predict(X_total_test_MLKR)\n",
    "    \n",
    "    r2_train_total = r2_score(y_total_train_kf, y_train_pred_total)\n",
    "    r2_test_total = r2_score(y_total_value_kf, y_test_pred_total)\n",
    "    \n",
    "    return (n, r2_train_motor, r2_test_motor, r2_train_total, r2_test_total)\n",
    "\n",
    "def process_m(n, kf, X_train_scaled, y_motor_train, y_total_train):\n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(process_fold)(train_i, value_i, n, X_train_scaled, y_motor_train, y_total_train)\n",
    "        for train_i, value_i in kf.split(X_train_scaled)\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "parallel_results = Parallel(n_jobs=-1)(\n",
    "    delayed(process_m)(n, kf, X_train_scaled, y_motor_train, y_total_train) for n in [n]\n",
    ")\n",
    "\n",
    "for result in parallel_results:\n",
    "    for fold_result in result:\n",
    "        print(f\"Components: {fold_result[0]}, R^2 Train Motor: {fold_result[1]}, R^2 Test Motor: {fold_result[2]}, R^2 Train Total: {fold_result[3]}, R^2 Test Total: {fold_result[4]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import r2_score\n",
    "from metric_learn import MLKR\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "path = './parkinsons_updrs.data'\n",
    "\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "X = data.drop(columns=['subject#', 'motor_UPDRS', 'total_UPDRS'])\n",
    "y_motor = data['motor_UPDRS']\n",
    "y_total = data['total_UPDRS']\n",
    "\n",
    "X_train, X_test, y_motor_train, y_motor_test, y_total_train, y_total_test = train_test_split(X, y_motor, y_total, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "n = 15\n",
    "\n",
    "pca_transformations = PCA(n_components=n).fit(X_train_scaled)\n",
    "\n",
    "def process_fold(train_i, value_i, n, X_train_scaled, y_motor_train, y_total_train):\n",
    "    X_train_kf, X_value_kf = X_train_scaled[train_i], X_train_scaled[value_i]\n",
    "    y_motor_train_kf, y_motor_value_kf = y_motor_train.iloc[train_i], y_motor_train.iloc[value_i]\n",
    "    y_total_train_kf, y_total_value_kf = y_total_train.iloc[train_i], y_total_train.iloc[value_i]\n",
    "    \n",
    "    X_motor_train_PCA = pca_transformations.transform(X_train_kf)\n",
    "    X_motor_test_PCA = pca_transformations.transform(X_value_kf)\n",
    "    \n",
    "    mlkr_motor = MLKR(n_components=n, init='pca')\n",
    "    mlkr_motor.fit(X_motor_train_PCA, y_motor_train_kf)\n",
    "    X_motor_train_MLKR = mlkr_motor.transform(X_motor_train_PCA)\n",
    "    X_motor_test_MLKR = mlkr_motor.transform(X_motor_test_PCA)\n",
    "    \n",
    "    gauss_kernel_motor = KernelRidge(kernel='rbf')\n",
    "    gauss_kernel_motor.fit(X_motor_train_MLKR, y_motor_train_kf)\n",
    "    \n",
    "    y_train_pred_motor = gauss_kernel_motor.predict(X_motor_train_MLKR)\n",
    "    y_test_pred_motor = gauss_kernel_motor.predict(X_motor_test_MLKR)\n",
    "    \n",
    "    r2_train_motor = r2_score(y_motor_train_kf, y_train_pred_motor)\n",
    "    r2_test_motor = r2_score(y_motor_value_kf, y_test_pred_motor)\n",
    "    \n",
    "    X_total_train_PCA = pca_transformations.transform(X_train_kf)\n",
    "    X_total_test_PCA = pca_transformations.transform(X_value_kf)\n",
    "    \n",
    "    mlkr_total = MLKR(n_components=n, init='pca')\n",
    "    mlkr_total.fit(X_total_train_PCA, y_total_train_kf)\n",
    "    X_total_train_MLKR = mlkr_total.transform(X_total_train_PCA)\n",
    "    X_total_test_MLKR = mlkr_total.transform(X_total_test_PCA)\n",
    "    \n",
    "    gauss_kernel_total = KernelRidge(kernel='rbf')\n",
    "    gauss_kernel_total.fit(X_total_train_MLKR, y_total_train_kf)\n",
    "    \n",
    "    y_train_pred_total = gauss_kernel_total.predict(X_total_train_MLKR)\n",
    "    y_test_pred_total = gauss_kernel_total.predict(X_total_test_MLKR)\n",
    "    \n",
    "    r2_train_total = r2_score(y_total_train_kf, y_train_pred_total)\n",
    "    r2_test_total = r2_score(y_total_value_kf, y_test_pred_total)\n",
    "    \n",
    "    return (n, r2_train_motor, r2_test_motor, r2_train_total, r2_test_total)\n",
    "\n",
    "def process_m(n, kf, X_train_scaled, y_motor_train, y_total_train):\n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(process_fold)(train_i, value_i, n, X_train_scaled, y_motor_train, y_total_train)\n",
    "        for train_i, value_i in kf.split(X_train_scaled)\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "parallel_results = Parallel(n_jobs=-1)(\n",
    "    delayed(process_m)(n, kf, X_train_scaled, y_motor_train, y_total_train) for n in [n]\n",
    ")\n",
    "\n",
    "for result in parallel_results:\n",
    "    for fold_result in result:\n",
    "        print(f\"Components: {fold_result[0]}, R^2 Train Motor: {fold_result[1]}, R^2 Test Motor: {fold_result[2]}, R^2 Train Total: {fold_result[3]}, R^2 Test Total: {fold_result[4]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import r2_score\n",
    "from metric_learn import MLKR\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "path = './parkinsons_updrs.data'\n",
    "\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "X = data.drop(columns=['subject#', 'motor_UPDRS', 'total_UPDRS'])\n",
    "y_motor = data['motor_UPDRS']\n",
    "y_total = data['total_UPDRS']\n",
    "\n",
    "X_train, X_test, y_motor_train, y_motor_test, y_total_train, y_total_test = train_test_split(X, y_motor, y_total, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "n = 19\n",
    "\n",
    "pca_transformations = PCA(n_components=n).fit(X_train_scaled)\n",
    "\n",
    "def process_fold(train_i, value_i, n, X_train_scaled, y_motor_train, y_total_train):\n",
    "    X_train_kf, X_value_kf = X_train_scaled[train_i], X_train_scaled[value_i]\n",
    "    y_motor_train_kf, y_motor_value_kf = y_motor_train.iloc[train_i], y_motor_train.iloc[value_i]\n",
    "    y_total_train_kf, y_total_value_kf = y_total_train.iloc[train_i], y_total_train.iloc[value_i]\n",
    "       \n",
    "    mlkr_motor = MLKR(n_components=n, init='auto')\n",
    "    mlkr_motor.fit(X_train_kf, y_motor_train_kf)\n",
    "    X_motor_train_MLKR = mlkr_motor.transform(X_train_kf)\n",
    "    X_motor_test_MLKR = mlkr_motor.transform(X_value_kf)\n",
    "    \n",
    "    gauss_kernel_motor = KernelRidge(kernel='rbf')\n",
    "    gauss_kernel_motor.fit(X_motor_train_MLKR, y_motor_train_kf)\n",
    "    \n",
    "    y_train_pred_motor = gauss_kernel_motor.predict(X_motor_train_MLKR)\n",
    "    y_test_pred_motor = gauss_kernel_motor.predict(X_motor_test_MLKR)\n",
    "    \n",
    "    r2_train_motor = r2_score(y_motor_train_kf, y_train_pred_motor)\n",
    "    r2_test_motor = r2_score(y_motor_value_kf, y_test_pred_motor)\n",
    "    \n",
    "    \n",
    "    mlkr_total = MLKR(n_components=n, init='auto')\n",
    "    mlkr_total.fit(X_train_kf, y_total_train_kf)\n",
    "    X_total_train_MLKR = mlkr_total.transform(X_train_kf)\n",
    "    X_total_test_MLKR = mlkr_total.transform(X_value_kf)\n",
    "    \n",
    "    gauss_kernel_total = KernelRidge(kernel='rbf')\n",
    "    gauss_kernel_total.fit(X_total_train_MLKR, y_total_train_kf)\n",
    "    \n",
    "    y_train_pred_total = gauss_kernel_total.predict(X_total_train_MLKR)\n",
    "    y_test_pred_total = gauss_kernel_total.predict(X_total_test_MLKR)\n",
    "    \n",
    "    r2_train_total = r2_score(y_total_train_kf, y_train_pred_total)\n",
    "    r2_test_total = r2_score(y_total_value_kf, y_test_pred_total)\n",
    "    \n",
    "    return (n, r2_train_motor, r2_test_motor, r2_train_total, r2_test_total)\n",
    "\n",
    "def process_m(n, kf, X_train_scaled, y_motor_train, y_total_train):\n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(process_fold)(train_i, value_i, n, X_train_scaled, y_motor_train, y_total_train)\n",
    "        for train_i, value_i in kf.split(X_train_scaled)\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "parallel_results = Parallel(n_jobs=-1)(\n",
    "    delayed(process_m)(n, kf, X_train_scaled, y_motor_train, y_total_train) for n in [n]\n",
    ")\n",
    "\n",
    "for result in parallel_results:\n",
    "    for fold_result in result:\n",
    "        print(f\"Components: {fold_result[0]}, R^2 Train Motor: {fold_result[1]}, R^2 Test Motor: {fold_result[2]}, R^2 Train Total: {fold_result[3]}, R^2 Test Total: {fold_result[4]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Use sklearn’s neural network implementation to train a neural network with two outputs that predicts motor UPDRS and total UPDRS. Use a single layer. You are responsible to determine other architectural parameters of the network, including the number of neurons in the hidden and output layers, method of optimization, type of activation functions, and the L2 “regularization” parameter etc. You should determine the design parameters via trial and error, by testing your trained network on the test set and choosing the architecture that yields the smallest test error. For this part, set early-stopping=False. Remember to standardize your features. Report your R^2 on both training and test sets. (20 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 on training set for motor UPDRS: 0.9591315893397608\n",
      "R^2 on training set for total UPDRS: 0.9641449844842482\n",
      "R^2 on test set for motor UPDRS: 0.8292075924024247\n",
      "R^2 on test set for total UPDRS: 0.8348681095343674\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "path = './parkinsons_updrs.data'\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "X = data.drop(columns=['subject#', 'motor_UPDRS', 'total_UPDRS'])\n",
    "y = data[['motor_UPDRS', 'total_UPDRS']]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "nn = MLPRegressor(hidden_layer_sizes=(200,), activation='tanh', solver='sgd', alpha=0.001, max_iter=5000, learning_rate_init=0.001, learning_rate='adaptive', random_state=42,early_stopping=False, validation_fraction=0.1)\n",
    "\n",
    "nn.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_pred = nn.predict(X_train_scaled)\n",
    "r2_train_motor = r2_score(y_train['motor_UPDRS'], y_train_pred[:, 0])\n",
    "r2_train_total = r2_score(y_train['total_UPDRS'], y_train_pred[:, 1])\n",
    "\n",
    "y_test_pred = nn.predict(X_test_scaled)\n",
    "r2_test_motor = r2_score(y_test['motor_UPDRS'], y_test_pred[:, 0])\n",
    "r2_test_total = r2_score(y_test['total_UPDRS'], y_test_pred[:, 1])\n",
    "\n",
    "print(f'R^2 on training set for motor UPDRS: {r2_train_motor}')\n",
    "print(f'R^2 on training set for total UPDRS: {r2_train_total}')\n",
    "print(f'R^2 on test set for motor UPDRS: {r2_test_motor}')\n",
    "print(f'R^2 on test set for total UPDRS: {r2_test_total}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d)Use the design parameters that you chose in the ﬁrst part and train a neural\n",
    "network, but this time set early-stopping=True. Research what early stopping is,\n",
    "and compare the performance of your network on the test set with the previous\n",
    "network. You can leave the validation-fraction as the default (0.1) or change it\n",
    "to see whether you can obtain a better model. Remember to standardize your\n",
    "features. Report your R2 on both training and test sets. (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 on training set for motor UPDRS: 0.9321351544702516\n",
      "R^2 on training set for total UPDRS: 0.9338009724721683\n",
      "R^2 on test set for motor UPDRS: 0.8119978743947998\n",
      "R^2 on test set for total UPDRS: 0.8058333276066811\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "path = './parkinsons_updrs.data'\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "X = data.drop(columns=['subject#', 'motor_UPDRS', 'total_UPDRS'])\n",
    "y = data[['motor_UPDRS', 'total_UPDRS']]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "nn = MLPRegressor(hidden_layer_sizes=(200,), activation='tanh', solver='sgd', alpha=0.0001, max_iter=5000, learning_rate_init=0.01, learning_rate='adaptive', random_state=42,early_stopping=True, validation_fraction=0.1)\n",
    "\n",
    "nn.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_pred = nn.predict(X_train_scaled)\n",
    "r2_train_motor = r2_score(y_train['motor_UPDRS'], y_train_pred[:, 0])\n",
    "r2_train_total = r2_score(y_train['total_UPDRS'], y_train_pred[:, 1])\n",
    "\n",
    "y_test_pred = nn.predict(X_test_scaled)\n",
    "r2_test_motor = r2_score(y_test['motor_UPDRS'], y_test_pred[:, 0])\n",
    "r2_test_total = r2_score(y_test['total_UPDRS'], y_test_pred[:, 1])\n",
    "\n",
    "print(f'R^2 on training set for motor UPDRS: {r2_train_motor}')\n",
    "print(f'R^2 on training set for total UPDRS: {r2_train_total}')\n",
    "print(f'R^2 on test set for motor UPDRS: {r2_test_motor}')\n",
    "print(f'R^2 on test set for total UPDRS: {r2_test_total}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With tuning I was able to get $R^2$ values in the 0.80s range, but still worse than without early stopping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
